<!DOCTYPE html>
<html>
<head>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>BOFormer</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Yu-Heng Hung</a><sup>*,1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Kai-Jie Lin</a><sup>*,1</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yu-Heng Lin</a><sup>1</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Chien-Yi Wang</a><sup>2</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Cheng Sun</a><sup>2</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Ping-Chun Hsieh</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan<br><sup>2</sup>NVIDIA Research<br></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openreview.net/pdf?id=UnCKU8pZVe" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/NYCU-RL-Bandits-Lab/BOFormer" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image Section -->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered has-text-weight-bold">
        BOFormer
      </h2>
      <div style="display: flex; justify-content: center;">
        <img src="static/images/BOFormer.jpg" 
           alt="BOFormer" 
           width="60%" 
           class="has-text-centered">
      </div>
    </div>
  </div>
</section> -->
<!-- End image section -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Bayesian optimization (BO) offers an efficient pipeline for optimizing black-box functions with the help of a Gaussian process prior and an acquisition function (AF). Recently, in the context of single-objective BO, learning-based AFs witnessed promising empirical results given its favorable non-myopic nature. Despite this, the direct extension of these approaches to multi-objective Bayesian optimization (MOBO) suffer from the hypervolume identifiability issue, which results from the non-Markovian nature of MOBO problems. To tackle this, inspired by the non-Markovian RL literature and the success of Transformers in language modeling, we present a generalized deep Q-learning framework and propose BOFormer, which substantiates this framework for MOBO via sequence modeling. Through extensive evaluation, we demonstrate that BOFormer constantly achieves better performance than the benchmark rule-based and learning-based algorithms in various synthetic MOBO and real-world multi-objective hyperparameter optimization problems.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Image Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Hypervolume Identifiability Issue</h2>
        <div class="content has-text-justified">
          <p>
            In single-objective Bayesian optimization, an RL-based AF (e.g., FSAF (Hsieh et al., 2021)) takes the posterior mean and standard deviation and the best function value observed so far as input and then outputs the AF value. An direct extension to MOBO simply takes into account the same set of information about all the $K$ objective functions. The hypervolume identifiability issue can be illustrated by comparing the hypervolume improvement incurred by the sample $x_3$ in the two different scenarios below. Clearly, despite that the AF inputs at $x_3$ are the same in both scenarios, the increases in hypervolume upon sampling $x_3$ are rather different. Hence, the increase in hypervolume is not identifiable solely based on the AF input of the existing RL-based AFs.
          </p>
        </div>
        <div style="display: flex; justify-content: center;">
          <img src="static/images/HV.png" 
             alt="HV" 
             width="150%" 
             class="has-text-centered">
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image section -->

<!-- Image Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Learning AF via Non-Markovian Q-Network</h2>
        <div style="display: flex; justify-content: center;">
          <img src="static/images/BOFormer.jpg" 
             alt="HV" 
             width="80%" 
             class="has-text-centered">
        </div>
        <div class="content has-text-justified">
          <p>
            To tackle hypervolume identifiability issue, we propose to rethink MOBO from the perspective of non-Markovian RL via sequence modeling. We propose BOFormer, which leverages the sequence modeling capability of the Transformer architecture and thereby minimizes the generalized temporal difference loss. BOFormer comprises two distinct networks as shown above: The upper network functions as the policy network, utilizing the historical data and the Q-value predicted by the target network to estimate the Q-values for action selection. The lower network serves as the target network, responsible for constructing Q-values for past observation-action pairs.
          </p>
    
          <h3>$Q$-Augmented Representation</h3> Define
          \begin{align*}
              y^{(i)*}_{t}:=\max\limits_{1\leq j\leq t}y^{(i)}_{i}, \forall i \in [1,\cdots,K]
          \end{align*}
          as the best observed function value of $i$-th objective up to time $t$. The observation-action pair for $x$ can be denoted by
          \begin{equation*}
              o_t(x) \equiv \Big\{\mu_t^{(i)}(x), \sigma_t^{(i)}(x),y_t^{(i)*} ,\frac{t}{T}\Big\}_{i\in [K]},
          \end{equation*}
          where $\mu_t^{(i)}(x):=\mathbb{E}[f_i(x)\rvert \mathcal{F}_t]$ and $\sigma_t^{(i)}(x):=\sqrt{\mathbb{V}[f_i(x)\rvert \mathcal{F}_t]}$ are the posterior predictive distribution under Gaussian Process (GP) prior. 
          <h3>BOFormer as an Acquisition Function for MOBO</h3>
          In BOFormer, we use the normalized hypervolume improvement as the reward, $\textit{i.e.}$, 
          \begin{equation*}
              r_t:=\frac{\text{HV}(\mathcal{X}_t)-\text{HV}(\mathcal{X}_{t-1})}{\text{HV}(\mathcal{X^*})-\text{HV}(\mathcal{X}_{t})}. 
          \end{equation*}
          Then, $h_t$, the history up to time $t$, is the concatenation of past observation-action pair representation defined as follows: 
        \begin{align}
            h_t  = \left\{\mu_j^{(i)}(x_j), \sigma_j^{(i)}(x_j), y_{j-1}^{(i)*}, j/t, r_i, Q_{\bar{\theta}}\right\}_{i\in[k], j\in[t-1]} \label{eq: state action}.
        \end{align}
        In non-Markovian RL, $Q_{\bar{\theta}}$ can be defined recursively, where 
        \begin{align*}
            Q_{\bar{\theta}}(h_t,o_t(x_t)):= Q_{\bar{\theta}}\left( \left\{ o_j(x_j), r_j, Q_{\bar{\theta}}(h_{j-1},o_{j-1}(x_{j-1})) \right\}_{j=1}^{t-1}, o_t(x_t)\right).
        \end{align*}
        Then, BOFormer selects the next sample point by letting $x_t = \text{argmax}_{x\in\mathcal{X}}Q_{\bar{\theta}}(h_t,o_t(x))$.
        <h3>Off-Policy Learning and Prioritized 
          Trajectory Replay Buffer</h3>
          We extend the concept of Prioritized Experience Replay (PER) and introduce the Prioritized Trajectory Replay Buffer (PTRB). The detailed modifications are as follows: (i) Elements pushed into this buffer are entire trajectories $\tau = \{o_i(x_i),r_i\}_{i=1}^T$. (ii) The TD-error considered in PER is replaced by $\delta(Q_{\theta_t},\tau)$, which is the summation of the TD-error of the policy network for all transitions in this trajectory, $\textit{i.e.}$, 
          \begin{align}
              \delta(Q,\tau) & := \sum_{i=1}^{T-1} \big( Q\left( h_i, o_i(x_i)\right)  -
              \big(r_i + \gamma \max_{x\in\mathbb{X}}Q_{\bar{\theta}}(h_{i+1}, o_{i+1}(x))\big) \big)^2.
          \end{align}
          Let $\mathcal{B}$ denote the batch sampled from PTRB. The loss function of BOFormer is defined as $L(\theta):=\sum_{\tau \in \mathcal{B}} \delta(Q_{\theta},\tau)$. For the training data, BOFormer is trained solely on synthetic GP functions, which are relatively cheap to generate (compared to real-world functions), and then be deployed to optimize unseen testing functions. 
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image section -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Table1.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          First image description.
        </h2> -->
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Table2.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          Second image description.
        </h2> -->
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Fig3.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
         Third image description.
       </h2> -->
      </div>
      <div class="item">
      <!-- Your image here -->
      <img src="static/images/Fig8.png" alt="MY ALT TEXT"/>
      <!-- <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2> -->
      
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Fig5.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          Fourth image description.
        </h2> -->
        
        </div>
  </div>
</div>
</div>
</section>

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Conclusion</h2>
      <div class="content has-text-justified">
        <p>
          In this paper, we address MOBO problems from the perspective of RL-based AF by identifying and tackling the inherent hypervolume identifiability issue. We achieve this goal by first presenting a generalized DQN framework and implementing it through BOFormer, which leverages the sequence modeling capability of Transformers and incorporates multiple enhancements for MOBO. Our experimental results show that BOFormer is indeed a promising approach for general-purpose multi-objective black-box optimization.
        </p>
      </div>
  </div>
</div>
</div>
</section>


<!-- End image carousel -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
        hung2025boformer,
        title={{BOF}ormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian {RL}},
        author={Yu Heng Hung and Kai-Jie Lin and Yu-Heng Lin and Chien-Yi Wang and Cheng Sun and Ping-Chun Hsieh},
        booktitle={The Thirteenth International Conference on Learning Representations},
        year={2025},
        url={https://openreview.net/forum?id=UnCKU8pZVe}
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
